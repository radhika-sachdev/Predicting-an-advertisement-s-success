---
title: "ML CASE STUDY"
output:
  html_document: default
  word_document: default
date: "23/02/2020"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

```

##AIM: To predict whether an investment on Ads is likely to generate a net gain for their clients


The holiday season is just around the corner—Christmas trees have been decorated, lights and wreaths hung, streets all decked up, Santa costumes rented out, and holiday cards in the mailbox. In light of this holiday cheer, retail brands, big and small, want to earn considerable profits, and therefore, are investing significantly in advertising. These brands have approached an advertising agency to plan and execute ad campaigns that will help them increase the footfall in their stores.

Here we have to assess the scope of revenue that can be generated by a proposed ad. Based on the demographic information provided, we are predicting whether the revenue generated will cover costs to produce and air the ad. This will help guide decision making for the firm, as they will want to pursue ads that are likely to generate a net gain for their clients— thereby bolstering the advertising firm’s reputation.

Data set consists of 12 variables out of which 9 are factor type variables. Our target variable is netgain, which is a binary variable containing values True and False. There are no missing values present in the data set.


```{r}

setwd("C:\\Users\\Radhika\\Desktop")
data_train <- read.csv("Ad_train.csv")
data_train <- data_train[,-1]
head(data_train)

str(data_train)

```

```{r knitr-logo, out.width='70%', fig.show='hold',fig.height=20}
knitr::include_graphics(rep('Picture1.png'))
```


```{r}
na_count <- sapply(data_train, function(y) sum(length(which(is.na(y)))))

na_count <- data.frame(na_count)

na_count
```

```{r}
a = table(data_train$netgain)
print(a)
```
Netgain occurs 6195 times out of the 26048 observed cases.

```{r}
summary(data_train)
```


```{r}
p=density(data_train$ratings)
plot(density(data_train$ratings))
polygon(p, col = 'blue')
```

We observe that the density plot of ratings is left skewed, which means that the targeted audience did not watch the advertisement. We can infer from this observation that the audience was not targeted efficiently. The company needs to invest in online as well as offline advertisements, to increase their reach.


```{r}
x = table(data_train$industry, data_train$netgain)
ratio = x[, 'true']/(x[, 'true'] + x[, 'false'])
x = cbind(x, ratio)

library(ggplot2)
library(dplyr)

x_df = as.data.frame(x)
x_df = setNames(cbind(rownames(x_df), x_df, row.names = NULL), c("industry", "false", "true", "ratio"))

x_df = x_df[order(x_df$ratio), ]

ggplot(x_df, aes(x=industry, y=ratio)) + 
  geom_bar(stat = "identity",color="black",fill="coral") +
  coord_flip() + ggtitle("Industry vs Netgain")
```


We observe that the best performing industry comes under the 'Others' category, followed by the Pharma Industry. It means that people respond well to advertisements promoting different brands of medicine. The Auto industry gets fairly covered on it's marketing campaign, whereas there is least return on investment on political advertising campaign.



```{r}
x = table(data_train$genre, data_train$netgain)
ratio = x[, 'true']/(x[, 'true'] + x[, 'false'])
x = cbind(x, ratio)

library(ggplot2)
library(dplyr)

x_df = as.data.frame(x)
x_df = setNames(cbind(rownames(x_df), x_df, row.names = NULL), c("genre", "false", "true", "ratio"))

x_df = x_df[order(x_df$ratio), ]

ggplot(x_df, aes(x=genre, y=ratio)) + 
  geom_bar(stat = "identity",color="black",fill="cornflowerblue") +
  coord_flip() + ggtitle("Genre vs Netgain")

```


Here we see how genre affects the netgain for their clients. It can be seen that people are attracted towards dramatic and funny advertisements more than those commercials that try to present a product in a direct manner(lacking creativity) or tries to present some information. It is generally observed that viewers tend to spend on a product or an idea when they are emotionally moved by the Ad, and this is clearly demonstrated with the netgain in the genres Drama and Comedy.



```{r}
x = table(data_train$airtime, data_train$netgain)
ratio = x[, 'true']/(x[, 'true'] + x[, 'false'])
x = cbind(x, ratio)

library(ggplot2)
library(dplyr)

x_df = as.data.frame(x)
x_df = setNames(cbind(rownames(x_df), x_df, row.names = NULL), c("airtime", "false", "true", "ratio"))

x_df = x_df[order(x_df$ratio), ]

ggplot(x_df, aes(x=airtime, y=ratio)) + 
  geom_bar(stat = "identity",color="black",fill="yellow") +
  coord_flip() + ggtitle("Airtime vs Netgain")

```


We observe that brands can cover advertising costs if they air the ad during Primetime. This is because the number of people using their TV sets during primetime is the highest. This is further followed by the Daytime viewership, and the ad is the least viewed during Morning hours. This could be possible because people rush for their work in the morning, and usually read the newspaper instead of using their TV sets. Thus the apt time to target their customer base is during Prime time.


```{r}
x = table(data_train$realtionship_status, data_train$netgain)
ratio = x[, 'true']/(x[, 'true'] + x[, 'false'])
x = cbind(x, ratio)

library(ggplot2)
library(dplyr)

x_df = as.data.frame(x)
x_df = setNames(cbind(rownames(x_df), x_df, row.names = NULL), c("relationship_status", "false", "true", "ratio"))

x_df = x_df[order(x_df$ratio), ]

ggplot(x_df, aes(x=relationship_status, y=ratio)) + 
  geom_bar(stat = "identity",color="black",fill="firebrick2") +
  coord_flip() + ggtitle("Relationship_Status vs Netgain")
```


Here we observe that the Married-civ-spouse should be targeted the most in their marketing campaign as they are responding well to the Ads. Next in line who could be targeted are Married-AF-spouse. Rest of the people are resulting approximately an equal amount of netgain to no netgain ratio, thus they need a better incentive to respond to an Ad. For example the Never-married people are tend to make impulse purchases, thus they could be targeted with better incentives and discounts.


```{r}
x = table(data_train$targeted_sex, data_train$netgain)
ratio = x[, 'true']/(x[, 'true'] + x[, 'false'])
x = cbind(x, ratio)

library(ggplot2)
library(dplyr)

x_df = as.data.frame(x)
x_df = setNames(cbind(rownames(x_df), x_df, row.names = NULL), c("gender", "false", "true", "ratio"))

x_df = x_df[order(x_df$ratio), ]

ggplot(x_df, aes(x=gender, y=ratio)) + 
  geom_bar(stat = "identity",color="black",fill="cyan3") +
  coord_flip()  + ggtitle("Gender vs Netgain")
```


We observe from the above plot that female to male ratio is very low. This means that the probablity of a netgain is higher, when males are spending on the products, which further means that either both the genders are not equally targeted for the Ad campaigns i.e the product is not communicated well to the females, or the product does not possess a good incentive for females.


```{r}
x = table(data_train$expensive, data_train$money_back_guarantee, data_train$netgain)
x_df = as.data.frame(x)
```

```{r}
high = filter(x_df, Var1 == "High")%>%select(Var2, Var3, Freq)
ratio = c()
for (i in 1:nrow(high))
{
  if ((high[i, 1]) == "No")
  {
    test = high[high$Var2 == "No", 3]
    sum1 = sum(test)
    ratio[i] = high[i, 3]/sum1
  }
  else
  {
    test = high[high$Var2 == "Yes", 3]
    sum1 = sum(test)
    ratio[i] = high[i, 3]/sum1
  }
}

high = cbind(high, ratio)
ggplot(high, aes(fill=Var3, y=ratio, x=Var2)) + 
    geom_bar(position="stack", stat="identity") +
    ggtitle("Highly Expensive") +
    xlab("Money Back Guarantee")
```

```{r}
medium = filter(x_df, Var1 == "Medium")%>%select(Var2, Var3, Freq)
ratio = c()
for (i in 1:nrow(medium))
{
  if ((medium[i, 1]) == "No")
  {
    test = medium[medium$Var2 == "No", 3]
    sum1 = sum(test)
    ratio[i] = medium[i, 3]/sum1
  }
  else
  {
    test = medium[medium$Var2 == "Yes", 3]
    sum1 = sum(test)
    ratio[i] = medium[i, 3]/sum1
  }
}

medium = cbind(medium, ratio)
ggplot(medium, aes(fill=Var3, y=ratio, x=Var2)) + 
    geom_bar(position="stack", stat="identity") +
    ggtitle("Medium Expensive") +
    xlab("Money Back Guarantee")

```
```{r}
low = filter(x_df, Var1 == "Low")%>%select(Var2, Var3, Freq)
ratio = c()
for (i in 1:nrow(low))
{
  if ((low[i, 1]) == "No")
  {
    test = low[low$Var2 == "No", 3]
    sum1 = sum(test)
    ratio[i] = low[i, 3]/sum1
  }
  else
  {
    test = low[low$Var2 == "Yes", 3]
    sum1 = sum(test)
    ratio[i] = low[i, 3]/sum1
  }
}

low = cbind(low, ratio)
ggplot(medium, aes(fill=Var3, y=ratio, x=Var2)) + 
    geom_bar(position="stack", stat="identity") +
    ggtitle("Low Expensive") +
    xlab("Money Back Guarantee")
```


From above three plots, we can see that a highly expensive product that ensures a money back guarantee, or a low cost product that does not give any money back guarantee, does not make a difference to the overall netgain of the company.



```{r}
x = table(data_train$expensive, data_train$netgain)
ratio = x[, 'true']/(x[, 'true'] + x[, 'false'])
x = cbind(x, ratio)

library(ggplot2)
library(dplyr)

x_df = as.data.frame(x)
x_df = setNames(cbind(rownames(x_df), x_df, row.names = NULL), c("expensive", "false", "true", "ratio"))

x_df = x_df[order(x_df$ratio), ]

ggplot(x_df, aes(x=expensive, y=ratio)) + 
  geom_bar(stat = "identity",color="black",fill="royalblue") +
  coord_flip() + ggtitle("Expensive vs Netgain")
```


From the above plot, we see that the price of the advertised commodity does not make a difference to a company's loss or gain, when sold. A slight rise in netgain is observed when the product is highly expensive. Hence it does not matter if the price of the product is high, low or medium, it will not make a significant difference in Netgain.



```{r}
x = table(data_train$money_back_guarantee, data_train$netgain)
ratio = x[, 'true']/(x[, 'true'] + x[, 'false'])
x = cbind(x, ratio)

library(ggplot2)
library(dplyr)

x_df = as.data.frame(x)
x_df = setNames(cbind(rownames(x_df), x_df, row.names = NULL), c("money_back", "false", "true", "ratio"))

x_df = x_df[order(x_df$ratio), ]

ggplot(x_df, aes(x=money_back, y=ratio)) + 
  geom_bar(stat = "identity",color="black",fill="maroon") +
  coord_flip() + ggtitle("Money back guarantee vs Netgain")
```


Money back guarantee is the refund offered in case of customer dissatisfaction. We observe that whether a refund is guaranteed or not, it does not affect the overall netgain significantly.



```{r}

library(plyr)
x = as.data.frame(table(data_train$industry, data_train$average_runtime.minutes_per_week.))
x$Var2 = as.integer(x$Var2)
x$tot_rt_ind = x$Var2 * x$Freq
x2 = ddply(x, .(Var1), summarise, tot_rt_ind=sum(tot_rt_ind))
x2
x3 = table(data_train$industry,data_train$netgain)
x2 = cbind(x2, x3[, 'true'])
scatter.smooth(x2$tot_rt_ind, x2$`x3[, "true"]`, xlab = "Total runtime per Industry", ylab = "Netgain (True)", main="Netgain vs Total runtime per Industry",col="red")
text(x2$tot_rt_ind, x2$`x3[, "true"]`,labels = x2$Var1, cex= 0.8, pos = 3)

```


We observe that as the total runtime per industry is increasing, the netgain is increasing too. This implies that if duration of the commercial is long enough, it tends to leave an impact on the viewers, which has a higher chance of resulting in a netgain. Maximum netgain is demonstrated in the Pharma industry.


```{r}
library(dplyr)
library(ggplot2)
x = filter(data_train, netgain == "true") %>% select(industry,targeted_sex)
x_df = as.data.frame(table(x))
x_df = ddply(x_df, .(industry), transform, ratio = round(((Freq / sum(Freq)) * 100), 0)) 

ggplot(x_df, aes(fill=targeted_sex, y=Freq, x=industry)) + ggtitle("When Netgain is true") +
geom_bar(position="stack", stat="identity") +
geom_text(data = x_df, aes(x = industry, label = paste0(ratio,"%")), size = 1.5 ,position=position_stack(0.5)) +
coord_flip()
```
```{r}
x = filter(data_train, netgain == "false") %>% select(industry,targeted_sex)
x_df = as.data.frame(table(x))
x_df = ddply(x_df, .(industry), transform, ratio = round(((Freq / sum(Freq)) * 100), 0)) 

ggplot(x_df, aes(fill=targeted_sex, y=Freq, x=industry)) + ggtitle("When Netgain is false") +
geom_bar(position="stack", stat="identity") +
geom_text(data = x_df, aes(x = industry, label = paste0(ratio,"%")), size = 1.5 ,position=position_stack(0.5)) +
coord_flip()
```


Here we have two plots depicting return on investment with respect to the targeted sex in various industries. We observe a peak in netgain when it comes to the Pharma industry.

From the above two plots, we can observe that maximum people result in a netgain in the Pharma industry. We see that out of 26048 people, 10339 males respond well to the Ads related to the Pharma industry.This means that they are more prone to spending on a medicine based on watching an advertisement about it. 

i)5740 people (22%) are not responding positively to the Ad campaign, and all of them are males.

ii)Only 4599 (17%) out of the whole population are resulting a gain for the industry. This gain is again fully contributed by the male community.

This implies the following points:
i) The female community was not efficiently targeted
ii)The medical information displayed does not cater to female needs

15709 -> attracted to industries other than Pharma

The second industry in line is the Auto industry, wherein 682 people respond positively to the Ad Campaign, i.e they contribute to company's netgain. Out of 682, males have a 61% share to their profit whereas females contribute 39%.

We also observe that around 6100 people do not respond well to the campaign of the Auto industry. Males again have a greater share than females.

This depicts that males take more interest in automobiles as compared to females, and they choose to spend on the product displayed in the commercial based on their interest and preference.

Similarly in the 'Others' category, only females tend to spend so that the company observes a netgain in their campaign. This category might include cosmetics or apparels for women.



```{r}
x = filter(data_train, netgain == "true") %>% select(genre,targeted_sex)
x_df = as.data.frame(table(x))
x_df = ddply(x_df, .(genre), transform, ratio = round(((Freq / sum(Freq)) * 100), 0)) 

ggplot(x_df, aes(fill=targeted_sex, y=Freq, x=genre)) + ggtitle("When Netgain is true") +
geom_bar(position="stack", stat="identity") +
geom_text(data = x_df, aes(x = genre, label = paste0(ratio,"%")), size = 1.5 ,position=position_stack(0.5)) +
coord_flip()
```
```{r}
x = filter(data_train, netgain == "false") %>% select(genre,targeted_sex)
x_df = as.data.frame(table(x))
x_df = ddply(x_df, .(genre), transform, ratio = round(((Freq / sum(Freq)) * 100), 0)) 

ggplot(x_df, aes(fill=targeted_sex, y=Freq, x=genre)) + ggtitle("When Netgain is false") +
geom_bar(position="stack", stat="identity") + geom_text(data = x_df, aes(x = genre, label = paste0(ratio,"%")), size = 1.5 ,position=position_stack(0.5)) + coord_flip()
```


As seen previously, people are attracted more towards the genre of comedy as compared to other genres. This is naturally true because any Ad that seems entertaining will increase viewership. We can see that out of 26048 people, 22258 people are attracted towards Comedy. 

From the above two plots, we observe that:

i) 16655 not responding positively to the Ad, i.e they must be watching or listening to the Ad but they are not resulting in a netgain for the company. Also, the majority of people not spending on the advertised commodity are males -> 63% males, 37% females

ii) Now  5603 are responding positively to the commercial, i.e. it is resulting into a gain for the company. Means the company has a return on investing on the Ad campaign only from 5603 people out of 26048 and the product is mostly purchased by Males again.-> 84% males, 16% females
    
3790 -> not responding to comedy genre

Second highest netgain is 'Infomercial' and lowest is observed in the 'Direct' genre category. 



```{r}
x = filter(data_train, netgain == "true") %>% select(realtionship_status,targeted_sex)
x_df = as.data.frame(table(x))
x_df = ddply(x_df, .(realtionship_status), transform, ratio = round(((Freq / sum(Freq)) * 100), 0)) 

ggplot(x_df, aes(fill=targeted_sex, y=Freq, x=realtionship_status)) + ggtitle("When Netgain is true") +
geom_bar(position="stack", stat="identity") +
geom_text(data = x_df, aes(x = realtionship_status, label = paste0(ratio,"%")), size = 1.5 ,position=position_stack(0.5)) +
coord_flip()
```
```{r}
x = filter(data_train, netgain == "false") %>% select(realtionship_status,targeted_sex)
x_df = as.data.frame(table(x))
x_df = ddply(x_df, .(realtionship_status), transform, ratio = round(((Freq / sum(Freq)) * 100), 0)) 

ggplot(x_df, aes(fill=targeted_sex, y=Freq, x=realtionship_status)) + ggtitle("When Netgain is false") +
geom_bar(position="stack", stat="identity") +
geom_text(data = x_df, aes(x = realtionship_status, label = paste0(ratio,"%")), size = 1.5, position=position_stack(0.5)) +
coord_flip()
```


From above two plots, we observe that never married people have a major response to that Ad Campaign because they are highest in number. Out of 8547 unmarried individuals, only 415 lead to a netgain, with 60:40 male to female ratio. Around 8132 persons do not respond well to the Advertisement, out of which 55% were males and 45% were females.

Next we can observe that the Married civ spouse have the best response towards commercials. About 5200 people tend to spend on the advertised product, among which 70% are males whereas only 30% are female buyers.

Around 6600 individuals out of the targeted lot, do not respond to the advertisement, thereby proving a loss in company's investment on Advertising Campaigns. Majority is again displayed by the males having an 88% share and women being 12%,in offering zero return on investment.


##VERIFYING ASSOCIATION BETWEEN CATEGORICAL VARIABLES USING CHI SQUARE TEST

H0: There is a significant association between the variables under study
H1: There is no significant association between the variables under study

```{r}
tab1<-table(data_train$genre,data_train$netgain)
tab1

chisq.test(data_train$genre,data_train$netgain)


tab2<-table(data_train$expensive,data_train$netgain)
tab2

chisq.test(data_train$expensive,data_train$netgain)


tab6<-table(data_train$airtime,data_train$netgain)
tab6

chisq.test(data_train$airtime,data_train$netgain)


tab8<-table(data_train$targeted_sex,data_train$netgain)
tab8

chisq.test(data_train$targeted_sex,data_train$netgain)


tab10<-table(data_train$industry,data_train$netgain)
tab10

chisq.test(data_train$industry,data_train$netgain)
```


For all the pair of variables, for which the p value is less than 0.05, there is significant association between the variables. For the pair Expensive and Netgain, the p value = 0.2531. Thus, as it was shown from the previous plots, the price of the product and overall netgain don't have a significant association. So even if the price of the commodity is low, it is not necessary that customers will be attracted to it and therbey lead to a netgain for the company.


##BUILDING MACHINE LEARNING MODELS

We now have 4 models and accuracy estimations for each. We need to compare the models with each other and select the most accurate.


##LOGISTIC REGRESSION

Logistic Regression is a classification algorithm. It is used to predict a binary outcome (1 / 0, Yes / No, True / False) given a set of independent variables. To represent binary/categorical outcome, we use dummy variables. 

It can be considered as a special case of linear regression when the outcome variable is categorical and it predicts the probability of occurrence of an event by fitting data to a logit function.


```{r}
data_train3 = data_train[, -7]
library(fastDummies)
results <- dummy_cols(data_train3)
results = results[, c(5, 7, 11:38, 10)]
results = results[, -c(3, 4, 6, 7, 8, 9, 15:20, 22, 25, 27:30)]
#results = results[, -9]

results$netgain = ifelse(results$netgain=="true",1,0)

sample.ind <- sample(2,nrow(results),replace = T,prob = c(0.6,0.4))
train <- results[sample.ind==1,]
test<- results[sample.ind==2,]

outcome = test[, 'netgain']
test = test[, -13]

logReg = glm(netgain ~ ., data = train, family = binomial)
pred <- predict(logReg, newdata = test, type = "response")
pred <- ifelse(pred > 0.5,1,0)
pred = as.factor(pred)
outcome = as.factor(outcome)

library(caret)
confusionMatrix(data=pred,reference=outcome,positive='1')
```


On applying Logistic Regression for binary classification, we see that 8371 observations were correctly predicted, giving an 80.16% prediction accuracy.



##DECISION TREE

A Decision Tree is a supervised learning predictive model that uses a set of binary rules to calculate a target value. 

It is used for either classification (categorical target variable) or regression (continuous target variable). Hence, it is also known as CART (Classification & Regression Trees).

Here we have a binary target variable, thus a Classification tree will be generated.

```{r}

class(data_train$netgain)

library(rpart)
library(rpart.plot)

#data_train = data_train[, -1]

sample.ind <- sample(2,nrow(data_train),replace = T,prob = c(0.6,0.4))
train <- data_train[sample.ind==1,]
test<- data_train[sample.ind==2,]

outcome = test[, 'netgain']
test = test[, -12]

table(train$netgain)/nrow(train)
table(test$netgain)/nrow(test)

decisionTree = rpart(netgain ~ ., data=train, method = "class", parms = list(split="gini"), control = rpart.control(cp = 8.042895e-04, maxdepth = 5))

rpart.plot(decisionTree)

plotcp(decisionTree)

pred <- predict(decisionTree, newdata = test, type = "class") 
library(caret)
confusionMatrix(data=pred,reference=outcome,positive='true')
```


The Decision tree model gives an 80.84% prediction accuracy.



##RANDOM FOREST

Random forests improve predictive accuracy by generating a large number of bootstrapped trees (based on random samples of variables), classifying a case using each tree in this new "forest", and deciding a final predicted outcome by combining the results across all of the trees. 

```{r}
dat.d <- sample(1:nrow(data_train),size=nrow(data_train)*0.60,replace = FALSE) #random selection of 70% data.
 
train <- data_train[dat.d,] # 60% training data
test <- data_train[-dat.d,] # remaining 40% test data

varNames <- names(data_train)
# Exclude ID or Response variable
varNames <- colnames(data_train[,-c(7,11)])

# add + sign between exploratory variables
varNames1 <- paste(varNames, collapse ="+")

rf.form <- as.formula(paste("netgain", varNames1, sep = "~"))

library(randomForest)

data_rf<-randomForest(rf.form, test ,ntree=78,importance=T)

varImpPlot(data_rf,sort = T,main="Variable Importance",n.var=5)

```


There are different ways to identify root nodes(important variables) and control how many splits are generated. CART uses Gini method to create binary splits.

i) GINI INDEX: It is the measure of inequality of distribution. It says if we select two items from a population at random then they must be of same class and probability for this is 1 if population is pure.

It works with categorical target variable “True” or “False”.

Lower the value of Gini, higher the homogeneity.


ii) ENTROPY: Entropy is a way to measure impurity. Less impure node require less information to describe them and more impure node require more information.


iii) INFORMATION GAIN: Information Gain is simply a mathematical way to capture the amount of information one gains(or reduction in randomness) by picking a particular attribute.

In a decision algorithm, we start at the tree root and split the data on the feature that results in the largest information gain (IG). In other words, IG tells us how important a given attribute is.


```{r}
library(e1071)
library(caret)

pred <- predict(data_rf,test)

confusionMatrix(data=pred,reference=test$netgain,positive='true')

class(test$netgain)
```


Using the Random Forest model, we can say that 84.28% of the observations were accurately predicted.



##KNN MODEL

KNN which stand for K Nearest Neighbor is a Supervised Machine Learning algorithm that classifies a new data point into the target class, depending on the features of its neighboring data points. 

*KNN is a non-parametric model which means that it does not make any assumptions about the data set. This makes the algorithm more effective since it can handle realistic data.*

KNN is a lazy algorithm, this means that it memorizes the training data set instead of learning a discriminative function from the training data.

KNN can be used for solving both classification and regression problems.


```{r}
set.seed(123)

data_train1<-data_train[,-c(7)]

data_train1$realtionship_status<-as.numeric(as.factor(data_train1$realtionship_status))

data_train1$industry<-as.numeric(as.factor(data_train1$industry))

data_train1$genre<-as.numeric(as.factor(data_train1$genre))
                                            
data_train1$targeted_sex<-as.numeric(as.factor(data_train1$targeted_sex))

data_train1$average_runtime.minutes_per_week.<-as.numeric(data_train1$average_runtime.minutes_per_week.)

data_train1$airtime<-as.numeric(as.factor(data_train1$airtime))

data_train1$expensive<-as.numeric(as.factor(data_train1$expensive))

data_train1$money_back_guarantee<-as.numeric(as.factor(data_train1$money_back_guarantee))

data_train1$netgain<-as.numeric(as.factor(data_train1$netgain))

dat.d <- sample(1:nrow(data_train1),size=nrow(data_train1)*0.7,replace = FALSE) #random selection of 70% data.
 
train <- data_train1[dat.d,] # 70% training data
test <- data_train1[-dat.d,] # remaining 30% test data

train_netgain <- data_train1[dat.d,10]
test_netgain <-data_train1[-dat.d,10]

library(class)

NROW(train_netgain)

sqrt(NROW(train_netgain))

knn.135 <- knn(train=train, test=test, cl=train_netgain, k=135)
knn.136 <- knn(train=train, test=test, cl=train_netgain, k=136)

ACC.135 <- 100 * sum(test_netgain == knn.135)/NROW(test_netgain)
ACC.135


ACC.136 <- 100 * sum(test_netgain == knn.136)/NROW(test_netgain)
ACC.136

table(knn.135 ,test_netgain)

table(knn.136 ,test_netgain)

library(caret)
confusionMatrix(table(knn.135 ,test_netgain))

confusionMatrix(table(knn.136 ,test_netgain))
```


We have 18233 observations in our training data set. The square root of 18233 is around 135.029, therefore we’ll create two models, one with k value as 135 and the other with 136. We then obtain the prediction accuracy using the confusion matrix. We see that the KNN model gives the highest prediction accuracy as compared to other models and correctly predicts Netgain 92.36% times.




